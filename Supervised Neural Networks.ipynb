{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.optimize\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from lasagne.updates import sgd, apply_momentum, nesterov_momentum, adagrad, adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='./data')\n",
    "y_all = mnist.target[:, np.newaxis]\n",
    "intercept = np.ones_like(y_all)\n",
    "data = np.hstack([intercept, mnist.data, y_all])\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(train, test):\n",
    "    \"\"\"Normalizes train set features to a standard normal distribution\n",
    "    (zero mean and unit variance). The same procedure is then applied\n",
    "    to the test set features.\n",
    "    \"\"\"\n",
    "    train_mean = train.mean(axis=0)\n",
    "    # +0.1 to avoid division by zero in this specific case\n",
    "    train_std = train.std(axis=0) + 0.1\n",
    "    \n",
    "    train = (train - train_mean) / train_std\n",
    "    test = (test - train_mean) / train_std\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_count = 60000\n",
    "Xt = data[:train_data_count, :-1]\n",
    "yt = data[:train_data_count, -1:].astype(int)\n",
    "\n",
    "\n",
    "Xv = data[train_data_count:, :-1]\n",
    "yv = data[train_data_count:, -1:].astype(int)\n",
    "\n",
    "Xt, Xv = normalize_features(Xt, Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binarizer = preprocessing.LabelBinarizer()\n",
    "binarizer.fit(yt)\n",
    "ytb = binarizer.transform(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape, m=0.01):\n",
    "    w = np.random.randn(*shape) * m\n",
    "    return theano.shared(floatX(w))\n",
    "\n",
    "def model(X, W, B):\n",
    "    h = X\n",
    "    for w, b in zip(W[:-1], B[:-1]):\n",
    "        z = T.dot(h, w) + b\n",
    "        h = T.maximum(z, 0)\n",
    "#         h = (T.exp(z) - T.exp(-z))/(T.exp(z) + T.exp(-z))\n",
    "    h = T.dot(h, W[-1]) + B[-1]\n",
    "    h = T.nnet.softmax(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Layers = [Xt.shape[1], 32, 10]\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "W = []\n",
    "B = []\n",
    "for l1, l2 in zip(Layers[:-1], Layers[1:]):\n",
    "    W.append(init_weights((l1, l2)))\n",
    "    B.append(init_weights((l2,), m=1))\n",
    "\n",
    "\n",
    "\n",
    "hwx = model(X, W, B)\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(hwx, Y))\n",
    "\n",
    "params = W + B\n",
    "\n",
    "# updates = sgd(cost, params, learning_rate=0.05)\n",
    "updates = nesterov_momentum(cost, params, learning_rate=0.05)\n",
    "\n",
    "predict = theano.function(inputs=[X], outputs=hwx, allow_input_downcast=True)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updates = sgd(cost, params, learning_rate=0.08)\n",
    "\n",
    "\n",
    "predict = theano.function(inputs=[X], outputs=hwx, allow_input_downcast=True)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train acc 0.9747 0.09103312360619488\n",
      "10 Train acc 0.974883333333 0.0905296149974597\n",
      "20 Train acc 0.975033333333 0.09003130004774981\n",
      "30 Train acc 0.97515 0.08953801985657879\n",
      "40 Train acc 0.975233333333 0.08905127552207501\n",
      "50 Train acc 0.975383333333 0.08857117892028628\n",
      "60 Train acc 0.975566666667 0.08809817466539215\n",
      "70 Train acc 0.975716666667 0.08763331761964013\n",
      "80 Train acc 0.975816666667 0.08717531140552698\n",
      "90 Train acc 0.975916666667 0.08672384808874312\n",
      "100 Train acc 0.976083333333 0.08627693582980304\n",
      "110 Train acc 0.97625 0.0858344724347057\n",
      "120 Train acc 0.97635 0.08539592132309573\n",
      "130 Train acc 0.976416666667 0.08496023318066206\n",
      "140 Train acc 0.9765 0.08452987419289588\n",
      "150 Train acc 0.976483333333 0.0841050824625499\n",
      "160 Train acc 0.97655 0.08368513798432844\n",
      "170 Train acc 0.976733333333 0.08327012713256803\n",
      "180 Train acc 0.9768 0.08286021566763188\n",
      "190 Train acc 0.976916666667 0.08245435581485278\n",
      "200 Train acc 0.977083333333 0.08205273788096352\n",
      "210 Train acc 0.977233333333 0.08165650959070621\n",
      "220 Train acc 0.977533333333 0.08126604125336807\n",
      "230 Train acc 0.977666666667 0.08087889252652748\n",
      "240 Train acc 0.977833333333 0.08049598556483095\n",
      "250 Train acc 0.978 0.08011679406677386\n",
      "260 Train acc 0.9781 0.07973995934578984\n",
      "270 Train acc 0.97815 0.07936430520044499\n",
      "280 Train acc 0.978283333333 0.07899086811115803\n",
      "290 Train acc 0.9784 0.07862092209926104\n",
      "300 Train acc 0.978516666667 0.07825342591820374\n",
      "310 Train acc 0.978666666667 0.07788907953991224\n",
      "320 Train acc 0.978783333333 0.07752825246647996\n",
      "330 Train acc 0.978816666667 0.07717065295134701\n",
      "340 Train acc 0.9789 0.07681538638397531\n",
      "350 Train acc 0.979166666667 0.07646287094901437\n",
      "360 Train acc 0.979266666667 0.07611293723989263\n",
      "370 Train acc 0.97935 0.07576702729554963\n",
      "380 Train acc 0.97945 0.07542427922248714\n",
      "390 Train acc 0.97955 0.0750827128952031\n",
      "400 Train acc 0.979616666667 0.07474292760563805\n",
      "410 Train acc 0.9797 0.07440625983573884\n",
      "420 Train acc 0.9798 0.07407102245638443\n",
      "430 Train acc 0.979933333333 0.07373642191802367\n",
      "440 Train acc 0.979966666667 0.07340554661035943\n",
      "450 Train acc 0.980016666667 0.0730787555906153\n",
      "460 Train acc 0.980066666667 0.0727553044978796\n",
      "470 Train acc 0.980083333333 0.07243346416103587\n",
      "480 Train acc 0.980116666667 0.07211427166617568\n",
      "490 Train acc 0.980183333333 0.07179826295362693\n",
      "500 Train acc 0.980233333333 0.07148557703703413\n",
      "510 Train acc 0.980316666667 0.07117573264574403\n",
      "520 Train acc 0.9804 0.07086762239901019\n",
      "530 Train acc 0.980533333333 0.07056055913049987\n",
      "540 Train acc 0.980616666667 0.07025515490644575\n",
      "550 Train acc 0.980733333333 0.06995092530984383\n",
      "560 Train acc 0.980833333333 0.06964856333258962\n",
      "570 Train acc 0.980933333333 0.06934839751210282\n",
      "580 Train acc 0.980966666667 0.06905036539632872\n",
      "590 Train acc 0.98105 0.0687543192125067\n",
      "600 Train acc 0.981216666667 0.06846043315530527\n",
      "610 Train acc 0.981316666667 0.06816725332716164\n",
      "620 Train acc 0.9814 0.06787595153808272\n",
      "630 Train acc 0.981483333333 0.06758644142242883\n",
      "640 Train acc 0.9816 0.0672992205254003\n",
      "650 Train acc 0.98165 0.06701356546150417\n",
      "660 Train acc 0.9817 0.06672961924801575\n",
      "670 Train acc 0.9818 0.06644664149795325\n",
      "680 Train acc 0.981866666667 0.06616528241508472\n",
      "690 Train acc 0.98205 0.06588519299556475\n",
      "700 Train acc 0.982166666667 0.06560691564237237\n",
      "710 Train acc 0.982233333333 0.06533084986978183\n",
      "720 Train acc 0.98225 0.06505722898360707\n",
      "730 Train acc 0.98235 0.06478578012411933\n",
      "740 Train acc 0.982433333333 0.06451613471138398\n",
      "750 Train acc 0.9825 0.06424839453619616\n",
      "760 Train acc 0.9827 0.06398196346074746\n",
      "770 Train acc 0.982766666667 0.06371690630346727\n",
      "780 Train acc 0.9828 0.0634521707355399\n",
      "790 Train acc 0.9829 0.06318760669375413\n",
      "800 Train acc 0.983016666667 0.06292352718580607\n",
      "810 Train acc 0.983083333333 0.06266134038842698\n",
      "820 Train acc 0.983116666667 0.06239986121965891\n",
      "830 Train acc 0.9832 0.06213934429780656\n",
      "840 Train acc 0.9833 0.06188046049518357\n",
      "850 Train acc 0.983416666667 0.0616238565461661\n",
      "860 Train acc 0.983483333333 0.06136766692783764\n",
      "870 Train acc 0.983533333333 0.06111287622851501\n",
      "880 Train acc 0.983583333333 0.060860226252554966\n",
      "890 Train acc 0.983766666667 0.0606090232354484\n",
      "900 Train acc 0.983916666667 0.06035850825499326\n",
      "910 Train acc 0.98395 0.06010919157653355\n",
      "920 Train acc 0.984016666667 0.05986088407055314\n",
      "930 Train acc 0.98415 0.05961399799123512\n",
      "940 Train acc 0.9842 0.05936872566304945\n",
      "950 Train acc 0.984216666667 0.059125581364737015\n",
      "960 Train acc 0.984333333333 0.058883586647307765\n",
      "970 Train acc 0.984366666667 0.058642946281856886\n",
      "980 Train acc 0.98445 0.05840338567955961\n",
      "990 Train acc 0.9845 0.058165654332316824\n",
      "CPU times: user 18min 51s, sys: 1min 29s, total: 20min 21s\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    cost = train(Xt, ytb)\n",
    "    if i % 10 == 0:\n",
    "        ytp = binarizer.inverse_transform(predict(Xt))\n",
    "        print(i, 'Train acc', accuracy_score(yt, ytp), cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('weights.pickle', 'wb') as f:\n",
    "    pickle.dump((W, B), f, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc 0.9845\n",
      "Valid acc 0.9529\n"
     ]
    }
   ],
   "source": [
    "ytp = binarizer.inverse_transform(predict(Xt))\n",
    "print('Train acc', accuracy_score(yt, ytp))\n",
    "yvp = binarizer.inverse_transform(predict(Xv))\n",
    "print('Valid acc', accuracy_score(yv, yvp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
