{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.optimize\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from lasagne.updates import sgd, apply_momentum, nesterov_momentum, adagrad, adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='./data')\n",
    "y_all = mnist.target[:, np.newaxis]\n",
    "intercept = np.ones_like(y_all)\n",
    "data = np.hstack([intercept, mnist.data, y_all])\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(train, test):\n",
    "    \"\"\"Normalizes train set features to a standard normal distribution\n",
    "    (zero mean and unit variance). The same procedure is then applied\n",
    "    to the test set features.\n",
    "    \"\"\"\n",
    "    train_mean = train.mean(axis=0)\n",
    "    # +0.1 to avoid division by zero in this specific case\n",
    "    train_std = train.std(axis=0) + 0.1\n",
    "    \n",
    "    train = (train - train_mean) / train_std\n",
    "    test = (test - train_mean) / train_std\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_count = 60000\n",
    "Xt = data[:train_data_count, :-1]\n",
    "yt = data[:train_data_count, -1:].astype(int)\n",
    "\n",
    "\n",
    "Xv = data[train_data_count:, :-1]\n",
    "yv = data[train_data_count:, -1:].astype(int)\n",
    "\n",
    "Xt, Xv = normalize_features(Xt, Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binarizer = preprocessing.LabelBinarizer()\n",
    "binarizer.fit(yt)\n",
    "ytb = binarizer.transform(yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def init_weights(shape, m=0.01):\n",
    "    w = np.random.randn(*shape) * m\n",
    "    return theano.shared(floatX(w))\n",
    "\n",
    "def model(X, W, B):\n",
    "    h = X\n",
    "    for w, b in zip(W[:-1], B[:-1]):\n",
    "        h = T.nnet.sigmoid(T.dot(h, w) + b)\n",
    "#     b = B[:-1]\n",
    "#     w = W[:-1]\n",
    "    h = T.dot(h, W[-1]) + B[-1]\n",
    "    h = T.nnet.softmax(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Layers = [Xt.shape[1], 256, 10]\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "W = []\n",
    "B = []\n",
    "for l1, l2 in zip(Layers[:-1], Layers[1:]):\n",
    "    W.append(init_weights((l1, l2)))\n",
    "    B.append(init_weights((l2,), m=1))\n",
    "\n",
    "\n",
    "\n",
    "hwx = model(X, W, B)\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(hwx, Y))\n",
    "\n",
    "params = W + B\n",
    "\n",
    "updates = sgd(cost, params, learning_rate=0.1)\n",
    "\n",
    "\n",
    "predict = theano.function(inputs=[X], outputs=hwx, allow_input_downcast=True)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = T.fmatrix()\n",
    "Y = T.fmatrix()\n",
    "\n",
    "def model(X, w_h, b_h, w_o, b_o):\n",
    "    h = X\n",
    "    h = T.nnet.sigmoid(T.dot(h, w_h) + b_h)\n",
    "    h = T.nnet.softmax(T.dot(h, w_o) + b_o)\n",
    "    return h\n",
    "\n",
    "w_h = init_weights((Xt.shape[1], 256))\n",
    "b_h = init_weights((256,))\n",
    "w_o = init_weights((256, 10))\n",
    "b_o = init_weights((10,))\n",
    "\n",
    "hwx = model(X, w_h, b_h, w_o, b_o)\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(hwx, Y))\n",
    "\n",
    "params = [w_h, b_h, w_o, b_o]\n",
    "\n",
    "updates = sgd(cost, params, learning_rate=0.1)\n",
    "\n",
    "\n",
    "predict = theano.function(inputs=[X], outputs=hwx, allow_input_downcast=True)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=updates, allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train acc 0.100766666667\n",
      "10 Train acc 0.14955\n",
      "20 Train acc 0.2194\n",
      "30 Train acc 0.3319\n",
      "40 Train acc 0.432416666667\n",
      "50 Train acc 0.501416666667\n",
      "60 Train acc 0.55075\n",
      "70 Train acc 0.592716666667\n",
      "80 Train acc 0.632016666667\n",
      "90 Train acc 0.6697\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    train(Xt, ytb)\n",
    "    if i % 10 == 0:\n",
    "        ytp = binarizer.inverse_transform(predict(Xt))\n",
    "        print(i, 'Train acc', accuracy_score(yt, ytp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc 0.765083333333\n",
      "Valid acc 0.7655\n"
     ]
    }
   ],
   "source": [
    "ytp = binarizer.inverse_transform(predict(Xt))\n",
    "print('Train acc', accuracy_score(yt, ytp))\n",
    "yvp = binarizer.inverse_transform(predict(Xv))\n",
    "print('Valid acc', accuracy_score(yv, yvp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
