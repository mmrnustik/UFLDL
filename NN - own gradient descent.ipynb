{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.optimize\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 1]]), array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [1]]))\n",
      "(array([[0, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 1]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [1]]))\n",
      "(array([[0, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 1]]), array([[0],\n",
      "       [1],\n",
      "       [1],\n",
      "       [0]]))\n"
     ]
    }
   ],
   "source": [
    "def data2numpy(D):\n",
    "    X = np.array([r[0] for r in D])\n",
    "    y = np.array([r[1] for r in D])\n",
    "    return X, y\n",
    "# [([data points], [targets])]\n",
    "data_AND = data2numpy([\n",
    "    ([0, 0], [0]), \n",
    "    ([0, 1], [0]),\n",
    "    ([1, 0], [0]),\n",
    "    ([1, 1], [1]),\n",
    "])\n",
    "\n",
    "data_OR = data2numpy([\n",
    "    ([0, 0], [0]), \n",
    "    ([0, 1], [1]),\n",
    "    ([1, 0], [1]),\n",
    "    ([1, 1], [1]),\n",
    "])\n",
    "\n",
    "data_XOR = data2numpy([\n",
    "    ([0, 0], [0]), \n",
    "    ([0, 1], [1]),\n",
    "    ([1, 0], [1]),\n",
    "    ([1, 1], [0]),\n",
    "])\n",
    "\n",
    "print(data_AND)\n",
    "print(data_OR)\n",
    "print(data_XOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.373153545703\n",
      "[[ 0.87921904  0.57838073]]\n",
      "[[ 0.83267177]\n",
      " [ 0.85403282]\n",
      " [ 0.85609302]\n",
      " [ 0.87020473]]\n",
      "\n",
      "100000 0.277991835435\n",
      "[[ 0.58154616  0.26513301]]\n",
      "[[ 0.6538734 ]\n",
      " [ 0.66639223]\n",
      " [ 0.66963752]\n",
      " [ 0.68116328]]\n",
      "\n",
      "200000 0.253291908335\n",
      "[[ 0.45937454  0.1130109 ]]\n",
      "[[ 0.55283985]\n",
      " [ 0.55613316]\n",
      " [ 0.55894391]\n",
      " [ 0.56212764]]\n",
      "\n",
      "300000 0.250379204136\n",
      "[[ 0.41966181  0.06066893]]\n",
      "[[ 0.51785445]\n",
      " [ 0.51852994]\n",
      " [ 0.52105448]\n",
      " [ 0.52167169]]\n",
      "\n",
      "400000 0.250037169852\n",
      "[[ 0.40404454  0.04300412]]\n",
      "[[ 0.50575046]\n",
      " [ 0.50563405]\n",
      " [ 0.50799159]\n",
      " [ 0.50783382]]\n",
      "\n",
      "500000 0.249997517294\n",
      "[[ 0.39625853  0.03722902]]\n",
      "[[ 0.50147113]\n",
      " [ 0.5010914 ]\n",
      " [ 0.50332642]\n",
      " [ 0.50291385]]\n",
      "\n",
      "600000 0.249994156535\n",
      "[[ 0.3912176   0.03557996]]\n",
      "[[ 0.49995179]\n",
      " [ 0.49947989]\n",
      " [ 0.50161059]\n",
      " [ 0.50111121]]\n",
      "\n",
      "result\n",
      "-0.000531587658633 [[ 0.49994573]\n",
      " [ 0.49947344]\n",
      " [ 0.50160345]\n",
      " [ 0.50110373]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class sigmoid:\n",
    "    def f(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def df(z):\n",
    "        s = sigmoid.f(z)\n",
    "        return s * (1 - s)\n",
    "\n",
    "class identity:\n",
    "    def f(z):\n",
    "        return z\n",
    "    \n",
    "    def df(z):\n",
    "        return 1\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    def __init__(self, inputs, neurons, activation_function, init_mult=0.9, alpha=0.001, regularization=.001):\n",
    "        self.ci = inputs\n",
    "        self.cn = neurons\n",
    "        self.fce = activation_function\n",
    "        self.W = np.random.rand(self.cn * self.ci) * init_mult\n",
    "        self.W = self.W.reshape((self.cn, self.ci))\n",
    "        self.b = np.random.rand(self.cn) * init_mult\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.regularization = regularization\n",
    "        \n",
    "    def ff(self, x):\n",
    "        self.a1 = x\n",
    "        self.z = x.dot(self.W.T)\n",
    "        self.z += self.b\n",
    "        self.a = self.fce.f(self.z)\n",
    "        return self.a\n",
    "    \n",
    "    def bb(self, d):\n",
    "        self.delta = d * self.fce.df(self.z)\n",
    "        delta = self.delta.dot(self.W)\n",
    "        return delta\n",
    "    \n",
    "    def gradient(self):\n",
    "        return self.delta.T.dot(self.a1), self.delta.sum(axis=0)\n",
    "    \n",
    "    def update(self, m):\n",
    "        gw, gb = self.gradient()\n",
    "        self.W -= self.alpha * (gw / m + self.regularization * self.W)\n",
    "        self.b -= self.alpha * gb / m\n",
    "    \n",
    "    def __mul__(self, x):\n",
    "        return self.W * x\n",
    "    \n",
    "    def __rmul__(self, x):\n",
    "        return x * self.W\n",
    "    \n",
    "    def dot(self, x):\n",
    "        return self.W.dot(x)\n",
    "\n",
    "    \n",
    "class FFNN():\n",
    "    def __init__(self, layers):\n",
    "        self.L = layers\n",
    "            \n",
    "    def forward_pass(self, X):\n",
    "        Xi = X\n",
    "        for l in self.L:\n",
    "            Xi = l.ff(Xi)\n",
    "        return Xi\n",
    "    \n",
    "    def backprop(self, d):\n",
    "        di = d\n",
    "        for l in reversed(self.L):\n",
    "            di = l.bb(di)\n",
    "    def update(self, m):\n",
    "        for l in self.L:\n",
    "            l.update(m)\n",
    "    \n",
    "    def decrease_alpha(self):\n",
    "        for l in self.L:\n",
    "            l.alpha *= 0.1\n",
    "    \n",
    "    def fit(self, X, y, n_iters=10000000):\n",
    "        oldd = np.inf\n",
    "        for i in range(n_iters):\n",
    "            yp = self.forward_pass(X)\n",
    "            d = -(y - yp)\n",
    "            e = (d ** 2).mean()\n",
    "            if oldd < e:\n",
    "                break\n",
    "            \n",
    "            self.backprop(d)\n",
    "            self.update(X.shape[0])\n",
    "            if i % 100000 == 0:\n",
    "                print(i, e)\n",
    "                print(self.L[-1].W)\n",
    "                print(yp)\n",
    "                print()\n",
    "            oldd = e\n",
    "                \n",
    "        \n",
    "\n",
    "# for X, y in [data_AND, data_OR, data_XOR]:    \n",
    "for X, y in [data_XOR]:        \n",
    "    layers = [\n",
    "        Layer(2, 2, sigmoid),\n",
    "        Layer(2, 1, sigmoid, alpha=0.0001)    \n",
    "    ]\n",
    "    nn = FFNN(layers)\n",
    "    nn.fit(X, y)\n",
    "    x=nn.forward_pass(X)\n",
    "    print(\"result\")\n",
    "    print(((x-y)).mean(), nn.forward_pass(X))\n",
    "    print()   \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00013081999999997596"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= [[ 0.5001287 ],\n",
    " [ 0.50013034],\n",
    " [ 0.5001313 ],\n",
    " [ 0.50013294]]\n",
    "-(x-y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original', data_home='./data')\n",
    "y_all = mnist.target[:, np.newaxis]\n",
    "intercept = np.ones_like(y_all)\n",
    "data = np.hstack([intercept, mnist.data, y_all])\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(train, test):\n",
    "    \"\"\"Normalizes train set features to a standard normal distribution\n",
    "    (zero mean and unit variance). The same procedure is then applied\n",
    "    to the test set features.\n",
    "    \"\"\"\n",
    "    train_mean = train.mean(axis=0)\n",
    "    # +0.1 to avoid division by zero in this specific case\n",
    "    train_std = train.std(axis=0) + 0.1\n",
    "    \n",
    "    train = (train - train_mean) / train_std\n",
    "    test = (test - train_mean) / train_std\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_count = 60000\n",
    "Xt = data[:train_data_count, :-1]\n",
    "yt = data[:train_data_count, -1:].astype(int)\n",
    "\n",
    "Xv = data[train_data_count:, :-1]\n",
    "yv = data[train_data_count:, -1:].astype(int)\n",
    "\n",
    "Xt, Xv = normalize_features(Xt, Xv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203786,)\n",
      "Training accuracy: 0.1134\n",
      "Test accuracy: 0.1073\n"
     ]
    }
   ],
   "source": [
    "class FFNN():\n",
    "    def __init__(self, layers_dims=[], activation_functions=[], regularization=1.1):\n",
    "        self.layers_dims = layers_dims\n",
    "        self.activation_functions = [None] + activation_functions\n",
    "        weights_size = 0\n",
    "        for i in range(1, len(self.layers_dims)):\n",
    "            weights_size += self.layers_dims[i-1] * self.layers_dims[i]\n",
    "        self.b_size = sum(layers_dims[1:])\n",
    "        self.weights = np.random.rand(self.b_size + weights_size) * 0.0001\n",
    "        print(self.weights.shape)\n",
    "        self.training_iterations = 0\n",
    "        self.lambd = regularization\n",
    "    \n",
    "    def next_iteration(self, weights):\n",
    "        self.training_iterations += 1\n",
    "        if self.training_iterations % 10 == 0:\n",
    "            print(\"Iteration:\", self.training_iterations, flush=True)\n",
    "            yvp = nn.forward_pass(Xv)\n",
    "            yvp = yvp.argmax(axis=1)\n",
    "            print('Training accuracy: {}'.format(accuracy_score(yt, ytp)), flush=True)\n",
    "    \n",
    "    def cost(self, weights, X, y):\n",
    "        nl = len(self.layers_dims) - 1\n",
    "        deltas = [None for i in range(nl + 1)]\n",
    "        \n",
    "        self.weights = weights\n",
    "        self.forward_pass(X, store_results=True)\n",
    "        a = self.a\n",
    "        z = self.z\n",
    "        B, W = self.unfold_weights(weights)\n",
    "        deltas[nl] = -(y - a[nl])\n",
    "        deltas[nl] *= self.activation_functions[nl].df(z[nl])\n",
    "        # deltas\n",
    "        for l in range(nl, 1, -1):\n",
    "            deltas[l-1] = deltas[l].dot(W[l]) * self.activation_functions[l-1].df(z[l-1])\n",
    "        weights_derivatives = []\n",
    "        b_derivatives = []\n",
    "        \n",
    "        # derivatives\n",
    "        for l in range(1, nl+1):\n",
    "            dW = deltas[l].T.dot(a[l-1])\n",
    "            weights_derivatives.append(dW.flatten())\n",
    "            b_derivatives.append(deltas[l].sum(axis=0).flatten())\n",
    "        cost = ((y - a[nl]) ** 2).sum() + self.lambd * (weights ** 2).sum()\n",
    "        gradient = np.hstack(b_derivatives + weights_derivatives)\n",
    "\n",
    "        assert gradient.shape == weights.shape\n",
    "        return cost, gradient\n",
    "    \n",
    "    def unfold_weights(self, weights):\n",
    "        used_count = self.b_size\n",
    "        used_bcount = 0\n",
    "        W = [None]\n",
    "        B = [None]\n",
    "        for i in range(1, len(self.layers_dims)):\n",
    "            m, n = self.layers_dims[i], self.layers_dims[i-1]\n",
    "            w = self.weights[used_count:used_count + (m * n)]\n",
    "            w = w.reshape((m, n))\n",
    "            b = self.weights[used_bcount:used_bcount + m]\n",
    "            W.append(w)\n",
    "            B.append(b)\n",
    "            used_count += m * n\n",
    "            used_bcount += m\n",
    "        return B, W\n",
    "            \n",
    "    def forward_pass(self, X, store_results=False):\n",
    "        used_count = self.b_size\n",
    "        used_bcount = 0\n",
    "        Xl = X\n",
    "        B, W = self.unfold_weights(self.weights)\n",
    "        if store_results:\n",
    "            self.a = [X]\n",
    "            self.z = [X]\n",
    "        for i in range(1, len(self.layers_dims)):\n",
    "            zl = Xl.dot(W[i].T) + B[i]\n",
    "            Xl = self.activation_functions[i].f(zl)\n",
    "            if store_results:\n",
    "                self.z.append(zl)\n",
    "                self.a.append(Xl)\n",
    "        return Xl \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        res = scipy.optimize.minimize(\n",
    "            fun=self.cost,\n",
    "            x0=self.weights,\n",
    "            args=(X, y),\n",
    "            method='L-BFGS-B',\n",
    "            jac=True,\n",
    "            tol=1e-5,\n",
    "            options={'maxiter': 500, 'disp': True},\n",
    "            callback=self.next_iteration,\n",
    "        )\n",
    "        self.weights = res.x\n",
    "\n",
    "\n",
    "\n",
    "le = preprocessing.LabelBinarizer()\n",
    "nn = FFNN([785, 256, 10], [sigmoid, sigmoid, sigmoid])\n",
    "# train \n",
    "ytt = le.fit_transform(yt)\n",
    "nn.fit(Xt, ytt)\n",
    "ytp = nn.forward_pass(Xt)\n",
    "ytp = ytp.argmax(axis=1)\n",
    "# test\n",
    "yvt = le.transform(yv)\n",
    "yvp = nn.forward_pass(Xv)\n",
    "yvp = yvp.argmax(axis=1)\n",
    "\n",
    "print('Training accuracy: {}'.format(accuracy_score(yt, ytp)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(yv, yvp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.70855\n",
      "Test accuracy: 0.6982\n"
     ]
    }
   ],
   "source": [
    "ytp = nn.forward_pass(Xt)\n",
    "ytp = ytp.argmax(axis=1)\n",
    "# test\n",
    "yvt = le.transform(yv)\n",
    "yvp = nn.forward_pass(Xv)\n",
    "yvp = yvp.argmax(axis=1)\n",
    "\n",
    "print('Training accuracy: {}'.format(accuracy_score(yt, ytp)))\n",
    "print('Test accuracy: {}'.format(accuracy_score(yv, yvp)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
